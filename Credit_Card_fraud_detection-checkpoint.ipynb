{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b6cf1-c458-4c88-91a5-333182672cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Measure script execution time\n",
    "t0 = time.time()\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Time consumed for imports:\", t1 - t0, \"seconds\")\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel(\"ProjectCreditCard.xlsx\")\n",
    "print(data.head())\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time consumed for loading data:\", t2 - t1, \"seconds\")\n",
    "\n",
    "# Basic dataset exploration\n",
    "data.info()\n",
    "pd.set_option(\"display.float\", \"{:.2f}\".format)\n",
    "print(\"Total missing values:\", data.isnull().sum().sum())\n",
    "print(\"Dataset columns:\", data.columns)\n",
    "\n",
    "t3 = time.time()\n",
    "print(\"Time consumed for initial exploration:\", t3 - t2, \"seconds\")\n",
    "\n",
    "# Class distribution visualization\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "count_classes = data['Class'].value_counts()\n",
    "count_classes.plot(kind='bar', rot=0)\n",
    "plt.title(\"Transaction Class Distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Data separation\n",
    "fraud = data[data['Class'] == 1]\n",
    "normal = data[data['Class'] == 0]\n",
    "print(f\"Fraudulent transactions: {fraud.shape}\")\n",
    "print(f\"Non-fraudulent transactions: {normal.shape}\")\n",
    "\n",
    "t4 = time.time()\n",
    "print(\"Time consumed for data separation:\", t4 - t3, \"seconds\")\n",
    "\n",
    "# Data preprocessing\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_v, y_train_v, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the fitted scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Scaler saved successfully!\")\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "w_p = class_counts.get(0, 0) / len(y_train)  # Non-fraud weight\n",
    "w_n = class_counts.get(1, 0) / len(y_train)  # Fraud weight\n",
    "\n",
    "print(f\"Fraud weight: {w_n}, Non-Fraud weight: {w_p}\")\n",
    "\n",
    "t6 = time.time()\n",
    "print(\"Time consumed for preprocessing:\", t6 - t4, \"seconds\")\n",
    "\n",
    "# ANN Model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[-1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy',\n",
    "              metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks and training\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('fraud_model_at_epoch_{epoch}.keras')]\n",
    "class_weight = {0: w_p, 1: w_n}\n",
    "\n",
    "r = model.fit(X_train, y_train, validation_data=(X_validate, y_validate),\n",
    "              batch_size=2048, epochs=300, callbacks=callbacks, class_weight=class_weight)\n",
    "\n",
    "t9 = time.time()\n",
    "print(\"Time consumed for training:\", t9 - t6, \"seconds\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"fraud_model.h5\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Model Evaluation\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Model evaluation:\", score)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(r.history['loss'], label='Loss')\n",
    "plt.plot(r.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Reload and test model\n",
    "print(\"Reloading the model for validation...\")\n",
    "fraud_model = load_model(\"fraud_model.h5\")\n",
    "\n",
    "# Recompile the model to include metrics\n",
    "fraud_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])\n",
    "\n",
    "# Load the saved scaler\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Apply the same preprocessing\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = fraud_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary class labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\n\", conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred, target_names=[\"Normal\", \"Fraud\"])\n",
    "print(\"Classification Report:\n\", class_report)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
