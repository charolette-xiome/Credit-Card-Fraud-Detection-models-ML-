{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b6cf1-c458-4c88-91a5-333182672cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Module to measure time intervals\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For plotting and data visualization\n",
    "import seaborn as sns  # For statistical data visualization\n",
    "\n",
    "# Measure start time for script execution\n",
    "t0 = time.time()\n",
    "\n",
    "# Set Seaborn style for better aesthetics in plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Measure end time for imports\n",
    "t1 = time.time()\n",
    "print(\"Time consumed for imports:\", t1 - t0, \"seconds\")\n",
    "\n",
    "# Load the dataset (ensure the file path is correct)\n",
    "data = pd.read_excel(\"ProjectCreditCard.xlsx\")\n",
    "print(data.head())  # Display the first few rows of the dataset\n",
    "\n",
    "# Measure time taken for loading the dataset\n",
    "t2 = time.time()\n",
    "print(\"Time consumed for loading data:\", t2 - t1, \"seconds\")\n",
    "\n",
    "# Display basic dataset information\n",
    "data.info()\n",
    "\n",
    "# Set display option for floating-point numbers\n",
    "pd.set_option(\"display.float\", \"{:.2f}\".format)\n",
    "\n",
    "# Display descriptive statistics of the dataset\n",
    "data.describe()\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "print(\"Total missing values:\", data.isnull().sum().sum())\n",
    "\n",
    "# Print column names for reference\n",
    "print(\"Dataset columns:\", data.columns)\n",
    "\n",
    "# Define class labels for visualization\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "\n",
    "# Visualize the class distribution\n",
    "count_classes = pd.value_counts(data['Class'], sort=True)\n",
    "count_classes.plot(kind='bar', rot=0)\n",
    "plt.title(\"Transaction Class Distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Count class distribution\n",
    "print(data.Class.value_counts())\n",
    "\n",
    "# Measure time taken for initial data exploration\n",
    "t3 = time.time()\n",
    "print(\"Time consumed for initial exploration:\", t3 - t2, \"seconds\")\n",
    "\n",
    "# Separate fraudulent and non-fraudulent transactions\n",
    "fraud = data[data['Class'] == 1]\n",
    "normal = data[data['Class'] == 0]\n",
    "\n",
    "# Display shapes of fraudulent and non-fraudulent data\n",
    "print(f\"Shape of fraudulent transactions: {fraud.shape}\")\n",
    "print(f\"Shape of non-fraudulent transactions: {normal.shape}\")\n",
    "\n",
    "# Compare descriptive statistics for transaction amounts\n",
    "print(pd.concat([fraud.Amount.describe(), normal.Amount.describe()], axis=1))\n",
    "\n",
    "# Measure time taken for data separation\n",
    "t4 = time.time()\n",
    "print(\"Time consumed for data separation:\", t4 - t3, \"seconds\")\n",
    "\n",
    "# Compare time distributions for fraudulent and non-fraudulent transactions\n",
    "print(pd.concat([fraud.Time.describe(), normal.Time.describe()], axis=1))\n",
    "\n",
    "# Plot the time distribution\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Time distribution for all transactions\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Time Distribution (Seconds)')\n",
    "sns.displot(data['Time'], color='blue')\n",
    "\n",
    "# Amount distribution for all transactions\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Distribution of Amount')\n",
    "sns.displot(data['Amount'], color='blue')\n",
    "\n",
    "# Histograms for time distributions\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Fraudulent transactions\n",
    "plt.subplot(2, 2, 1)\n",
    "data[data.Class == 1].Time.hist(bins=35, color='blue', alpha=0.6, label=\"Fraudulent Transactions\")\n",
    "plt.legend()\n",
    "\n",
    "# Non-fraudulent transactions\n",
    "plt.subplot(2, 2, 2)\n",
    "data[data.Class == 0].Time.hist(bins=35, color='blue', alpha=0.6, label=\"Non-Fraudulent Transactions\")\n",
    "plt.legend()\n",
    "\n",
    "# Heatmap for correlation analysis\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(data=data.corr(), cmap=\"seismic\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Measure time taken for visualization\n",
    "t5 = time.time()\n",
    "print(\"Time consumed for visualization:\", t5 - t4, \"seconds\")\n",
    "\n",
    "# ========================\n",
    "# DATA PREPROCESSING\n",
    "# ========================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize a standard scaler\n",
    "scalar = StandardScaler()\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data.Class\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_v, y_train_v, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_validate = scalar.transform(X_validate)\n",
    "X_test = scalar.transform(X_test)\n",
    "\n",
    "# Calculate class weights for imbalance handling\n",
    "w_p = y_train.value_counts()[0] / len(y_train)  # Weight for non-fraudulent class\n",
    "w_n = y_train.value_counts()[1] / len(y_train)  # Weight for fraudulent class\n",
    "\n",
    "# Print class weights and dataset shapes\n",
    "print(f\"Fraudulent transaction weight: {w_n}\")\n",
    "print(f\"Non-Fraudulent transaction weight: {w_p}\")\n",
    "print(f\"TRAINING: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"VALIDATION: X_validate: {X_validate.shape}, y_validate: {y_validate.shape}\")\n",
    "print(f\"TESTING: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Measure time taken for preprocessing\n",
    "t6 = time.time()\n",
    "print(\"Time consumed for preprocessing:\", t6 - t5, \"seconds\")\n",
    "\n",
    "# Import necessary libraries for evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Function to print evaluation metrics for training and testing\n",
    "def print_score(label, prediction, train=True):\n",
    "    if train:\n",
    "        # Generate classification report as a DataFrame\n",
    "        clf_report = pd.DataFrame(classification_report(label, prediction, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(label, prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, prediction)}\\n\")\n",
    "    elif train == False:\n",
    "        # Generate classification report for test data\n",
    "        clf_report = pd.DataFrame(classification_report(label, prediction, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(label, prediction) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(label, prediction)}\\n\")\n",
    "\n",
    "# Measure and print time taken for metrics calculation\n",
    "t7 = time.time()\n",
    "print(\"Time consumed:\", t7 - t6, \"sec\")\n",
    "\n",
    "# Importing TensorFlow's Keras library for building the ANN model\n",
    "from tensorflow import keras\n",
    "\n",
    "# Building the ANN model with multiple dense layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[-1],)),  # Input layer\n",
    "    keras.layers.BatchNormalization(),  # Normalize layer output\n",
    "    keras.layers.Dropout(0.3),  # Dropout for regularization\n",
    "    keras.layers.Dense(256, activation='relu'),  # Hidden layer 1\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(256, activation='relu'),  # Hidden layer 2\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Measure and print time taken for model building\n",
    "t8 = time.time()\n",
    "print(\"Time consumed:\", t8 - t7, \"sec\")\n",
    "\n",
    "# Define evaluation metrics for the model\n",
    "METRICS = [\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "# Define callback to save the model at each epoch\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('fraud_model_at_epoch_{epoch}.keras')]\n",
    "\n",
    "# Set class weights to handle class imbalance\n",
    "class_weight = {0: w_p, 1: w_n}\n",
    "\n",
    "# Train the model with the training data\n",
    "r = model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_validate, y_validate),  # Validation data\n",
    "    batch_size=2048,  # Batch size\n",
    "    epochs=300,  # Number of epochs\n",
    "    callbacks=callbacks,  # Model checkpoint callback\n",
    ")\n",
    "\n",
    "# Measure and print time taken for training\n",
    "t9 = time.time()\n",
    "print(\"Time consumed:\", t9 - t8, \"sec\")\n",
    "\n",
    "# Evaluate the model on test data and print metrics\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "# Plot training metrics over epochs\n",
    "plt.figure(figsize=(12, 16))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(r.history['loss'], label='Loss')\n",
    "plt.plot(r.history['val_loss'], label='val_Loss')\n",
    "plt.title('Loss Function evolution during training')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(r.history['fn'], label='fn')\n",
    "plt.plot(r.history['val_fn'], label='val_fn')\n",
    "plt.title('False Negatives evolution during training')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(r.history['precision'], label='Precision')\n",
    "plt.plot(r.history['val_precision'], label='val_Precision')\n",
    "plt.title('Precision evolution during training')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(r.history['recall'], label='Recall')\n",
    "plt.plot(r.history['val_recall'], label='val_Recall')\n",
    "plt.title('Recall evolution during training')\n",
    "plt.legend()\n",
    "\n",
    "# Generate predictions for training and test data\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics for training and test data\n",
    "print_score(y_train, y_train_pred.round(), train=True)\n",
    "print_score(y_test, y_test_pred.round(), train=False)\n",
    "\n",
    "# Save F1 scores for comparison\n",
    "scores_dict = {\n",
    "    'ANNs': {\n",
    "        'Train': f1_score(y_train, y_train_pred.round()),\n",
    "        'Test': f1_score(y_test, y_test_pred.round()),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Measure and print time taken for evaluation\n",
    "t10 = time.time()\n",
    "print(\"Time consumed:\", t10 - t9, \"sec\")\n",
    "\n",
    "# Import Random Forest classifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=False)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for training and test data\n",
    "y_train_pred = rf_clf.predict(X_train)\n",
    "y_test_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics for Random Forest model\n",
    "print_score(y_train, y_train_pred, train=True)\n",
    "print_score(y_test, y_test_pred, train=False)\n",
    "\n",
    "# Save F1 scores for comparison\n",
    "scores_dict['Random Forest'] = {\n",
    "    'Train': f1_score(y_train, y_train_pred),\n",
    "    'Test': f1_score(y_test, y_test_pred),\n",
    "}\n",
    "\n",
    "# Measure and print time taken for Random Forest training and evaluation\n",
    "t11 = time.time()\n",
    "print(\"Time consumed:\", t11 - t10, \"sec\")\n",
    "\n",
    "# Import LightGBM classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Train LightGBM classifier\n",
    "lgbm_clf = LGBMClassifier()\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for training and test data\n",
    "y_train_pred = lgbm_clf.predict(X_train)\n",
    "y_test_pred = lgbm_clf.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics for LightGBM model\n",
    "print_score(y_train, y_train_pred, train=True)\n",
    "print_score(y_test, y_test_pred, train=False)\n",
    "\n",
    "# Save F1 scores for comparison\n",
    "scores_dict['LigthGBM'] = {\n",
    "    'Train': f1_score(y_train, y_train_pred),\n",
    "    'Test': f1_score(y_test, y_test_pred),\n",
    "}\n",
    "\n",
    "# Measure and print total time consumed\n",
    "t12 = time.time()\n",
    "print(\"Time consumed:\", t12 - t11, \"sec\")\n",
    "print(\"Total time consumed:\", t12 - t0, \"sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
